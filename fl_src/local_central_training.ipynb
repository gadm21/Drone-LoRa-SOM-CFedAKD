{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import errno\n",
    "import argparse\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from data_utils import load_CIFAR_data, generate_partial_data, generate_bal_private_data, load_FEMNIST_data, load_MNIST_data\n",
    "from FedMD import FedMD\n",
    "from Neural_Networks import train_models, cnn_2layer_fc_model, cnn_3layer_fc_model\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import clone_model, load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "from utility import * \n",
    "from data_utils import generate_alignment_data\n",
    "from Neural_Networks import remove_last_layer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions and Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-10 config\n",
    "\n",
    "CANDIDATE_MODELS = {\"2_layer_CNN\": cnn_2layer_fc_model, \n",
    "                    \"3_layer_CNN\": cnn_3layer_fc_model} \n",
    "\n",
    "conf_file = os.path.abspath(\"conf/CIFAR_balance_conf.json\")\n",
    "\n",
    "with open(conf_file, \"r\") as f:\n",
    "    conf_dict = eval(f.read())\n",
    "    \n",
    "    #n_classes = conf_dict[\"n_classes\"]\n",
    "    model_config = conf_dict[\"models\"]\n",
    "    pre_train_params = conf_dict[\"pre_train_params\"]\n",
    "    model_saved_dir = conf_dict[\"model_saved_dir\"]\n",
    "    model_saved_names = conf_dict[\"model_saved_names\"]\n",
    "    is_early_stopping = conf_dict[\"early_stopping\"]\n",
    "    public_classes = conf_dict[\"public_classes\"]\n",
    "    private_classes = conf_dict[\"private_classes\"]\n",
    "    n_classes = len(public_classes) + len(private_classes)\n",
    "    \n",
    "    emnist_data_dir = conf_dict[\"EMNIST_dir\"]    \n",
    "    N_parties = conf_dict[\"N_parties\"]\n",
    "    N_samples_per_class = conf_dict[\"N_samples_per_class\"]\n",
    "    \n",
    "    N_rounds = conf_dict[\"N_rounds\"]\n",
    "    N_alignment = conf_dict[\"N_alignment\"]\n",
    "    N_private_training_round = conf_dict[\"N_private_training_round\"]\n",
    "    private_training_batchsize = conf_dict[\"private_training_batchsize\"]\n",
    "    N_logits_matching_round = conf_dict[\"N_logits_matching_round\"]\n",
    "    logits_matching_batchsize = conf_dict[\"logits_matching_batchsize\"]\n",
    "    aug = conf_dict[\"aug\"]\n",
    "    compress = conf_dict[\"compress\"]\n",
    "    \n",
    "    \n",
    "    result_save_dir = conf_dict[\"result_save_dir\"]\n",
    "\n",
    "del conf_dict, conf_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEMNIST conifg\n",
    "\n",
    "CANDIDATE_MODELS = {\"2_layer_CNN\": cnn_2layer_fc_model, \n",
    "                    \"3_layer_CNN\": cnn_3layer_fc_model} \n",
    "\n",
    "conf_file = os.path.abspath(\"conf/EMNIST_balance_conf.json\")\n",
    "with open(conf_file, \"r\") as f:\n",
    "    conf_dict = eval(f.read())\n",
    "    \n",
    "    #n_classes = conf_dict[\"n_classes\"]\n",
    "    model_config = conf_dict[\"models\"]\n",
    "    pre_train_params = conf_dict[\"pre_train_params\"]\n",
    "    model_saved_dir = conf_dict[\"model_saved_dir\"]\n",
    "    model_saved_names = conf_dict[\"model_saved_names\"]\n",
    "    is_early_stopping = conf_dict[\"early_stopping\"]\n",
    "    public_classes = conf_dict[\"public_classes\"]\n",
    "    private_classes = conf_dict[\"private_classes\"]\n",
    "    n_classes = len(public_classes) + len(private_classes)\n",
    "    \n",
    "    emnist_data_dir = conf_dict[\"EMNIST_dir\"]    \n",
    "    N_parties = conf_dict[\"N_parties\"]\n",
    "    N_samples_per_class = conf_dict[\"N_samples_per_class\"]\n",
    "    \n",
    "    N_rounds = conf_dict[\"N_rounds\"]\n",
    "    N_alignment = conf_dict[\"N_alignment\"]\n",
    "    N_private_training_round = conf_dict[\"N_private_training_round\"]\n",
    "    private_training_batchsize = conf_dict[\"private_training_batchsize\"]\n",
    "    N_logits_matching_round = conf_dict[\"N_logits_matching_round\"]\n",
    "    logits_matching_batchsize = conf_dict[\"logits_matching_batchsize\"]\n",
    "    \n",
    "    \n",
    "    result_save_dir = conf_dict[\"result_save_dir\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_samples_per_class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CIFAR10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape : (50000, 32, 32, 3)\n",
      "X_test shape : (10000, 32, 32, 3)\n",
      "y_train shape : (50000,)\n",
      "y_test shape : (10000,)\n",
      "X_train shape : (50000, 32, 32, 3)\n",
      "X_test shape : (10000, 32, 32, 3)\n",
      "y_train shape : (50000,)\n",
      "y_test shape : (10000,)\n",
      "X shape : (3000, 32, 32, 3)\n",
      "y shape : (3000,)\n",
      "X shape : (600, 32, 32, 3)\n",
      "y shape : (600,)\n",
      "10    500\n",
      "15    500\n",
      "14    500\n",
      "12    500\n",
      "13    500\n",
      "11    500\n",
      "dtype: int64\n",
      "============================================================\n",
      "============================================================\n",
      "X shape : (600, 32, 32, 3)\n",
      "y shape : (600,)\n",
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-01 17:57:27.940421: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-08-01 17:57:27.942579: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/Users/gadmohamed/miniforge3/envs/env_tf/lib/python3.9/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 0 : CNN_128_256\n",
      "model 1 : CNN_128_384\n",
      "model 2 : CNN_128_512\n",
      "model 3 : CNN_256_256\n",
      "model 4 : CNN_256_512\n",
      "model 5 : CNN_64_128_256\n",
      "model 6 : CNN_64_128_192\n",
      "model 7 : CNN_128_192_256\n",
      "model 8 : CNN_128_128_128\n",
      "model 9 : CNN_128_128_192\n",
      "model 10 : CNN_128_256\n",
      "model 11 : CNN_128_384\n",
      "model 12 : CNN_128_512\n",
      "model 13 : CNN_256_256\n",
      "model 14 : CNN_256_512\n",
      "model 15 : CNN_64_128_256\n",
      "model 16 : CNN_64_128_192\n",
      "model 17 : CNN_128_192_256\n",
      "model 18 : CNN_128_128_128\n",
      "model 19 : CNN_128_128_192\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_train_CIFAR10, y_train_CIFAR10, X_test_CIFAR10, y_test_CIFAR10 \\\n",
    "= load_CIFAR_data(data_type=\"CIFAR10\", \n",
    "                    standarized = True, verbose = True)\n",
    "\n",
    "public_dataset = {\"X\": X_train_CIFAR10, \"y\": y_train_CIFAR10}\n",
    "\n",
    "\n",
    "X_train_CIFAR100, y_train_CIFAR100, X_test_CIFAR100, y_test_CIFAR100 \\\n",
    "= load_CIFAR_data(data_type=\"CIFAR100\",\n",
    "                    standarized = True, verbose = True)\n",
    "\n",
    "# only use those CIFAR100 data whose y_labels belong to private_classes\n",
    "X_train_CIFAR100, y_train_CIFAR100 \\\n",
    "= generate_partial_data(X = X_train_CIFAR100, y= y_train_CIFAR100,\n",
    "                        class_in_use = private_classes, \n",
    "                        verbose = True)\n",
    "\n",
    "\n",
    "X_test_CIFAR100, y_test_CIFAR100 \\\n",
    "= generate_partial_data(X = X_test_CIFAR100, y= y_test_CIFAR100,\n",
    "                        class_in_use = private_classes, \n",
    "                        verbose = True)\n",
    "\n",
    "# relabel the selected CIFAR100 data for future convenience\n",
    "for index, cls_ in enumerate(private_classes):        \n",
    "    y_train_CIFAR100[y_train_CIFAR100 == cls_] = index + len(public_classes)\n",
    "    y_test_CIFAR100[y_test_CIFAR100 == cls_] = index + len(public_classes)\n",
    "del index, cls_\n",
    "\n",
    "print(pd.Series(y_train_CIFAR100).value_counts())\n",
    "mod_private_classes = np.arange(len(private_classes)) + len(public_classes)\n",
    "\n",
    "print(\"=\"*60)\n",
    "#generate private data\n",
    "private_data, total_private_data\\\n",
    "=generate_bal_private_data(X_train_CIFAR100, y_train_CIFAR100,      \n",
    "                            N_parties = N_parties,           \n",
    "                            classes_in_use = mod_private_classes, \n",
    "                            N_samples_per_class = N_samples_per_class, \n",
    "                            data_overlap = False)\n",
    "\n",
    "print(\"=\"*60)\n",
    "X_tmp, y_tmp = generate_partial_data(X = X_test_CIFAR100, y= y_test_CIFAR100,\n",
    "                                        class_in_use = mod_private_classes, \n",
    "                                        verbose = True)\n",
    "private_test_data = {\"X\": X_tmp, \"y\": y_tmp}\n",
    "del X_tmp, y_tmp\n",
    "\n",
    "parties = []\n",
    "if model_saved_dir is None:\n",
    "    for i, item in enumerate(model_config):\n",
    "        model_name = item[\"model_type\"]\n",
    "        model_params = item[\"params\"]\n",
    "        tmp = CANDIDATE_MODELS[model_name](n_classes=n_classes, \n",
    "                                            input_shape=(32,32,3),\n",
    "                                            **model_params)\n",
    "        print(\"model {0} : {1}\".format(i, model_saved_names[i]))\n",
    "        # print(tmp.summary())\n",
    "        parties.append(tmp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load FASHION MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST dataset ... \n",
      "X_train shape : (60000, 28, 28)\n",
      "X_test shape : (10000, 28, 28)\n",
      "y_train shape : (60000,)\n",
      "y_test shape : (10000,)\n",
      "shape: (60000,)\n",
      "unique: [0 1 2 3 4 5 6 7 8 9]\n",
      "EMNIST-letter dataset ... \n",
      "X_train shape : (60000, 28, 28)\n",
      "X_test shape : (10000, 28, 28)\n",
      "y_train shape : (60000,)\n",
      "y_test shape : (10000,)\n",
      "y train femnist unique: [ 9 10 11 12 13 14 15 16 17 18]\n",
      "y test femnist unique: [ 9 10 11 12 13 14 15 16 17 18]\n",
      "private classes: [10, 11, 12, 13, 14, 15]\n",
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 22:12:23.449555: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-08-11 22:12:23.449919: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/Users/gadmohamed/miniforge3/envs/env_tf/lib/python3.9/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train_MNIST, y_train_MNIST, X_test_MNIST, y_test_MNIST \\\n",
    "= load_MNIST_data(standarized = True, verbose = True)\n",
    "\n",
    "public_dataset = {\"X\": X_train_MNIST, \"y\": y_train_MNIST}\n",
    "\n",
    "\n",
    "X_train_EMNIST, y_train_EMNIST, X_test_EMNIST, y_test_EMNIST \\\n",
    "= load_FEMNIST_data(standarized = True, verbose = True)\n",
    "\n",
    "y_train_EMNIST = y_train_EMNIST + len(public_classes)\n",
    "y_test_EMNIST = y_test_EMNIST + len(public_classes)\n",
    "\n",
    "print(\"y train femnist unique:\", np.unique(y_train_EMNIST))\n",
    "print(\"y test femnist unique:\", np.unique(y_test_EMNIST)) \n",
    "print(\"private classes:\", private_classes)\n",
    "\n",
    "#generate private data\n",
    "private_data, total_private_data \\\n",
    "= generate_bal_private_data(X_train_EMNIST, y_train_EMNIST, \n",
    "                            N_parties = N_parties,             \n",
    "                            classes_in_use = private_classes, \n",
    "                            N_samples_per_class = N_samples_per_class, \n",
    "                            data_overlap = False)\n",
    "\n",
    "X_tmp, y_tmp = generate_partial_data(X = X_test_EMNIST, y= y_test_EMNIST, \n",
    "                                        class_in_use = private_classes, verbose = True)\n",
    "private_test_data = {\"X\": X_tmp, \"y\": y_tmp}\n",
    "del X_tmp, y_tmp\n",
    "\n",
    "parties = []\n",
    "if model_saved_dir is None:\n",
    "    for i in range(N_parties):\n",
    "\n",
    "        item = np.random.choice(model_config)\n",
    "        model_name = item[\"model_type\"]\n",
    "        model_params = item[\"params\"]\n",
    "        tmp = CANDIDATE_MODELS[model_name](n_classes=n_classes, \n",
    "                                            input_shape=(28,28),\n",
    "                                            **model_params)\n",
    "        # print(\"model {0} : {1}\".format(i, model_saved_names[i]))\n",
    "        # print(tmp.summary())\n",
    "        parties.append(tmp)\n",
    "        \n",
    "        del model_name, model_params, tmp\n",
    "    #END FOR LOOP\n",
    "#     pre_train_result = train_models(parties, \n",
    "#                                     X_train_MNIST, y_train_MNIST, \n",
    "#                                     X_test_MNIST, y_test_MNIST,\n",
    "#                                     save_dir = model_saved_dir, save_names = model_saved_names,\n",
    "#                                     early_stopping = is_early_stopping,\n",
    "#                                     **pre_train_params\n",
    "#                                    )\n",
    "else:\n",
    "    dpath = os.path.abspath(model_saved_dir)\n",
    "    model_names = os.listdir(dpath)\n",
    "    for name in model_names:\n",
    "        tmp = None\n",
    "        tmp = load_model(os.path.join(dpath ,name))\n",
    "        parties.append(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3136.0, 7914.496, 20)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_of(public_dataset['X'][:500]), size_of(parties[0]), len(parties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 28, 28) (600, 28, 28) (600, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "new_total_private_data = {}\n",
    "new_total_private_data['X'] = np.concatenate([p['X'] for p in private_data ], axis = 0)\n",
    "new_total_private_data['y'] = np.concatenate([p['y'] for p in private_data ], axis = 0)\n",
    "\n",
    "print(private_data[0]['X'].shape, total_private_data['X'].shape, new_total_private_data['X'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gadmohamed/miniforge3/envs/env_tf/lib/python3.9/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-08-11 22:13:30.311728: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-08-11 22:13:30.721381: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-11 22:13:32.263793: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final accuracy: 0.3738333284854889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 22:14:42.932857: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-11 22:14:44.216782: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final accuracy: 0.47316667437553406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 22:16:29.173915: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-11 22:16:30.687625: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final accuracy: 0.5299999713897705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 22:17:51.113109: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-11 22:17:51.716606: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final accuracy: 0.4569999873638153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 22:19:26.758365: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-11 22:19:27.923400: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final accuracy: 0.32883334159851074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 22:20:33.712263: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-11 22:20:34.301590: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final accuracy: 0.3621666729450226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 22:22:04.189711: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-11 22:22:04.791776: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final accuracy: 0.5366666913032532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 22:23:11.298539: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-11 22:23:11.907083: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final accuracy: 0.5173333287239075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 22:24:48.351392: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-11 22:24:49.491230: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final accuracy: 0.6244999766349792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 22:25:44.814058: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-11 22:25:46.124887: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final accuracy: 0.4411666691303253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 22:27:25.968349: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-11 22:27:26.602980: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final accuracy: 0.4698333442211151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 22:29:18.691751: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-11 22:29:19.262621: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final accuracy: 0.5770000219345093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 22:30:36.101371: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-11 22:30:37.261508: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final accuracy: 0.35899999737739563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 22:31:36.428143: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-11 22:31:36.980460: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final accuracy: 0.4101666808128357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 22:32:53.837465: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-11 22:32:54.421759: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final accuracy: 0.46016666293144226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 22:34:07.514523: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-11 22:34:07.986119: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final accuracy: 0.5331666469573975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 22:35:20.062641: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-11 22:35:21.238670: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final accuracy: 0.2601666748523712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 22:36:56.939733: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-11 22:36:57.384239: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final accuracy: 0.5133333206176758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 22:39:01.666266: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-11 22:39:02.108028: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final accuracy: 0.42933332920074463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 22:40:36.900499: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-11 22:40:37.319651: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final accuracy: 0.3894999921321869\n"
     ]
    }
   ],
   "source": [
    "input_shape = private_data[0][\"X\"].shape[1:]\n",
    "# [0.5483333468437195, 0.5421666502952576, 0.6263333559036255, 0.4596666693687439, 0.5808333158493042, 0.6393333077430725, 0.6313333511352539, 0.5663333535194397, 0.5171666741371155, 0.503333330154419]\n",
    "\n",
    "local_accuracies = [] \n",
    "for i in range(len(private_data)):\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    item = model_config[0]\n",
    "    model_name = item[\"model_type\"]\n",
    "    model_params = item[\"params\"]\n",
    "    model_ub = CANDIDATE_MODELS[model_name](n_classes=n_classes, \n",
    "                                        input_shape=input_shape,\n",
    "                                        **model_params)\n",
    "    model_ub.compile(optimizer=tf.keras.optimizers.Adam(lr = 1e-3),\n",
    "                        loss = \"sparse_categorical_crossentropy\", \n",
    "                        metrics = [\"accuracy\"])\n",
    "    ub_history = model_ub.fit(private_data[i]['X'], private_data[i]['y'],\n",
    "                    batch_size = 30, epochs = 30, shuffle=True, verbose = False, \n",
    "                    validation_data = [private_test_data[\"X\"], private_test_data[\"y\"]],\n",
    "                    callbacks=[EarlyStopping(monitor=\"val_accuracy\", min_delta=0.001, patience=7, restore_best_weights=True)])\n",
    "\n",
    "    local_accuracies.append(ub_history.history[\"val_accuracy\"])\n",
    "    print(\"final accuracy:\", ub_history.history[\"val_accuracy\"][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4523166656494141"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([acc[-1] for acc in local_accuracies])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average: 0.4523166656494141\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data for the bar plot\n",
    "accuracies = [0.5483333468437195, 0.5421666502952576, 0.6263333559036255, 0.4596666693687439, 0.5808333158493042, 0.6393333077430725, 0.6313333511352539, 0.5663333535194397, 0.5171666741371155, 0.503333330154419]\n",
    "accuracies = [acc[-1] for acc in local_accuracies]\n",
    "# Clients for the x-axis (assuming one accuracy value per client)\n",
    "clients = range(1, len(accuracies) + 1)\n",
    "\n",
    "# Create a figure and axes for the plot\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "# Plot the bar chart with custom colors, edgecolor, and width\n",
    "bars = ax.bar(clients, accuracies, color='steelblue', edgecolor='black', width=0.5, label = 'Local Accuracy')\n",
    "\n",
    "# Add values on top of the bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.annotate(f'{height:.3f}', xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),\n",
    "                textcoords=\"offset points\", ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Set x and y axis labels and title\n",
    "ax.set_xlabel('Clients')\n",
    "ax.set_ylabel('Final Accuracy')\n",
    "ax.set_title('Accuracies of Clients\\' Local Training')\n",
    "\n",
    "# Add a horizontal line at accuracy 70 to mark it as the central accuracy\n",
    "central_avg_acc = np.mean([acc[-1] for acc in central_trials])\n",
    "ax.axhline(y=central_avg_acc, color='red', linestyle='--', label='Central Accuracy')\n",
    "\n",
    "# Add a horizontal line for the average accuracy local \n",
    "ax.axhline(y=sum(accuracies)/len(accuracies), color='green', linestyle='--', label='Average Local Accuracy')\n",
    "\n",
    "print(\"average:\", sum(accuracies)/len(accuracies))\n",
    "# Add a grid to the plot\n",
    "ax.grid(axis='y', linestyle='dotted')\n",
    "\n",
    "# Adjust the layout to avoid cutting off labels\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add a legend with position right bottom\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Save the plot as a high-quality PDF\n",
    "plt.savefig('local_central.pdf', dpi=300)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gadmohamed/miniforge3/envs/env_tf/lib/python3.9/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shpae of private data: (30, 28, 28)\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 22:50:34.505245: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - ETA: 0s - loss: 3.9085 - accuracy: 0.5383"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 22:50:38.372358: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 10s 459ms/step - loss: 3.9085 - accuracy: 0.5383 - val_loss: 1.4930 - val_accuracy: 0.5148\n",
      "Epoch 2/40\n",
      "20/20 [==============================] - 10s 496ms/step - loss: 1.3443 - accuracy: 0.7967 - val_loss: 2.3889 - val_accuracy: 0.2138\n",
      "Epoch 3/40\n",
      "20/20 [==============================] - 8s 419ms/step - loss: 0.8844 - accuracy: 0.8250 - val_loss: 2.7279 - val_accuracy: 0.1667\n",
      "Epoch 4/40\n",
      "20/20 [==============================] - 8s 418ms/step - loss: 0.5324 - accuracy: 0.8650 - val_loss: 3.4125 - val_accuracy: 0.1667\n",
      "Epoch 5/40\n",
      "20/20 [==============================] - 9s 450ms/step - loss: 0.4867 - accuracy: 0.8933 - val_loss: 4.1790 - val_accuracy: 0.1667\n",
      "Epoch 6/40\n",
      "20/20 [==============================] - 8s 422ms/step - loss: 0.4392 - accuracy: 0.9067 - val_loss: 5.4352 - val_accuracy: 0.1667\n",
      "Epoch 7/40\n",
      "20/20 [==============================] - 8s 402ms/step - loss: 0.3335 - accuracy: 0.9133 - val_loss: 5.6761 - val_accuracy: 0.1667\n",
      "Epoch 8/40\n",
      "20/20 [==============================] - 5s 248ms/step - loss: 0.2438 - accuracy: 0.9417 - val_loss: 5.4221 - val_accuracy: 0.1667\n",
      "Epoch 9/40\n",
      "20/20 [==============================] - 6s 302ms/step - loss: 0.2126 - accuracy: 0.9467 - val_loss: 5.2660 - val_accuracy: 0.2052\n",
      "Epoch 10/40\n",
      "20/20 [==============================] - 7s 339ms/step - loss: 0.1905 - accuracy: 0.9467 - val_loss: 5.0477 - val_accuracy: 0.1667\n",
      "Epoch 11/40\n",
      "20/20 [==============================] - 8s 427ms/step - loss: 0.1762 - accuracy: 0.9650 - val_loss: 4.8122 - val_accuracy: 0.2053\n",
      "Epoch 12/40\n",
      "20/20 [==============================] - 6s 307ms/step - loss: 0.2327 - accuracy: 0.9450 - val_loss: 6.1612 - val_accuracy: 0.1667\n",
      "Epoch 13/40\n",
      "20/20 [==============================] - 5s 281ms/step - loss: 0.1661 - accuracy: 0.9633 - val_loss: 5.7107 - val_accuracy: 0.1670\n",
      "Epoch 14/40\n",
      "20/20 [==============================] - 5s 267ms/step - loss: 0.1253 - accuracy: 0.9717 - val_loss: 5.3254 - val_accuracy: 0.1665\n",
      "Epoch 15/40\n",
      "20/20 [==============================] - 7s 342ms/step - loss: 0.1537 - accuracy: 0.9667 - val_loss: 3.6748 - val_accuracy: 0.2135\n",
      "Epoch 16/40\n",
      "20/20 [==============================] - 6s 330ms/step - loss: 0.2006 - accuracy: 0.9583 - val_loss: 2.8733 - val_accuracy: 0.3987\n",
      "Epoch 17/40\n",
      "20/20 [==============================] - 7s 346ms/step - loss: 0.2529 - accuracy: 0.9533 - val_loss: 3.0856 - val_accuracy: 0.3668\n",
      "Epoch 18/40\n",
      "20/20 [==============================] - 7s 345ms/step - loss: 0.1444 - accuracy: 0.9750 - val_loss: 2.2733 - val_accuracy: 0.4303\n",
      "Epoch 19/40\n",
      "20/20 [==============================] - 6s 310ms/step - loss: 0.1559 - accuracy: 0.9667 - val_loss: 1.5530 - val_accuracy: 0.5625\n",
      "Epoch 20/40\n",
      "20/20 [==============================] - 9s 442ms/step - loss: 0.2960 - accuracy: 0.9400 - val_loss: 1.1912 - val_accuracy: 0.6355\n",
      "Epoch 21/40\n",
      "20/20 [==============================] - 5s 246ms/step - loss: 0.2009 - accuracy: 0.9650 - val_loss: 1.3169 - val_accuracy: 0.6215\n",
      "Epoch 22/40\n",
      "20/20 [==============================] - 6s 310ms/step - loss: 0.1556 - accuracy: 0.9733 - val_loss: 1.1928 - val_accuracy: 0.6727\n",
      "Epoch 23/40\n",
      "20/20 [==============================] - 9s 445ms/step - loss: 0.1027 - accuracy: 0.9767 - val_loss: 0.9621 - val_accuracy: 0.7497\n",
      "Epoch 24/40\n",
      "20/20 [==============================] - 6s 310ms/step - loss: 0.0819 - accuracy: 0.9800 - val_loss: 1.5466 - val_accuracy: 0.6792\n",
      "Epoch 25/40\n",
      "20/20 [==============================] - 8s 436ms/step - loss: 0.0755 - accuracy: 0.9917 - val_loss: 1.3422 - val_accuracy: 0.7103\n",
      "Epoch 26/40\n",
      "20/20 [==============================] - 7s 361ms/step - loss: 0.0780 - accuracy: 0.9900 - val_loss: 1.1549 - val_accuracy: 0.7528\n",
      "Epoch 27/40\n",
      "20/20 [==============================] - 5s 273ms/step - loss: 0.1028 - accuracy: 0.9900 - val_loss: 1.7465 - val_accuracy: 0.6465\n",
      "Epoch 28/40\n",
      "20/20 [==============================] - 6s 290ms/step - loss: 0.0549 - accuracy: 0.9983 - val_loss: 1.2984 - val_accuracy: 0.7542\n",
      "Epoch 29/40\n",
      "20/20 [==============================] - 5s 267ms/step - loss: 0.0475 - accuracy: 0.9933 - val_loss: 1.1823 - val_accuracy: 0.7942\n",
      "Epoch 30/40\n",
      "20/20 [==============================] - 6s 314ms/step - loss: 0.0488 - accuracy: 0.9967 - val_loss: 1.2497 - val_accuracy: 0.7937\n",
      "Epoch 31/40\n",
      "20/20 [==============================] - 7s 349ms/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 1.2931 - val_accuracy: 0.8072\n",
      "Epoch 32/40\n",
      "20/20 [==============================] - 8s 434ms/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 1.3880 - val_accuracy: 0.8110\n",
      "Epoch 33/40\n",
      "20/20 [==============================] - 6s 329ms/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 1.4624 - val_accuracy: 0.8112\n",
      "Epoch 34/40\n",
      "20/20 [==============================] - 6s 294ms/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 1.5126 - val_accuracy: 0.8165\n",
      "Epoch 35/40\n",
      "20/20 [==============================] - 6s 294ms/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 1.5669 - val_accuracy: 0.8195\n",
      "Epoch 36/40\n",
      "20/20 [==============================] - 7s 363ms/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 1.6552 - val_accuracy: 0.8117\n",
      "Epoch 37/40\n",
      "20/20 [==============================] - 7s 345ms/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 1.6859 - val_accuracy: 0.8205\n",
      "Epoch 38/40\n",
      "20/20 [==============================] - 7s 362ms/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 1.7817 - val_accuracy: 0.8150\n",
      "Epoch 39/40\n",
      "20/20 [==============================] - 7s 340ms/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 1.7795 - val_accuracy: 0.8243\n",
      "Epoch 40/40\n",
      "20/20 [==============================] - 7s 351ms/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 1.8079 - val_accuracy: 0.8218\n",
      "final accuracy: 0.8218333125114441\n",
      "shpae of private data: (30, 28, 28)\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 22:55:07.323244: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - ETA: 0s - loss: 3.6706 - accuracy: 0.5500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 22:55:09.818225: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 9s 425ms/step - loss: 3.6706 - accuracy: 0.5500 - val_loss: 1.4718 - val_accuracy: 0.3995\n",
      "Epoch 2/40\n",
      "20/20 [==============================] - 5s 260ms/step - loss: 1.2722 - accuracy: 0.7483 - val_loss: 2.5147 - val_accuracy: 0.1867\n",
      "Epoch 3/40\n",
      "20/20 [==============================] - 7s 382ms/step - loss: 1.1319 - accuracy: 0.8300 - val_loss: 4.0447 - val_accuracy: 0.1667\n",
      "Epoch 4/40\n",
      "20/20 [==============================] - 8s 407ms/step - loss: 0.7634 - accuracy: 0.8583 - val_loss: 4.8695 - val_accuracy: 0.1905\n",
      "Epoch 5/40\n",
      "20/20 [==============================] - 7s 367ms/step - loss: 0.5466 - accuracy: 0.8983 - val_loss: 4.5242 - val_accuracy: 0.2132\n",
      "Epoch 6/40\n",
      "20/20 [==============================] - 8s 409ms/step - loss: 0.3399 - accuracy: 0.9200 - val_loss: 6.2862 - val_accuracy: 0.1667\n",
      "Epoch 7/40\n",
      "20/20 [==============================] - 6s 285ms/step - loss: 0.3756 - accuracy: 0.9083 - val_loss: 5.5360 - val_accuracy: 0.2318\n",
      "Epoch 8/40\n",
      "20/20 [==============================] - 5s 254ms/step - loss: 0.3788 - accuracy: 0.9233 - val_loss: 6.2084 - val_accuracy: 0.1737\n",
      "Epoch 9/40\n",
      "20/20 [==============================] - 5s 280ms/step - loss: 0.3774 - accuracy: 0.9183 - val_loss: 7.5437 - val_accuracy: 0.2132\n",
      "Epoch 10/40\n",
      "20/20 [==============================] - 9s 445ms/step - loss: 0.3523 - accuracy: 0.9400 - val_loss: 7.2632 - val_accuracy: 0.1863\n",
      "Epoch 11/40\n",
      "20/20 [==============================] - 10s 519ms/step - loss: 0.3832 - accuracy: 0.9200 - val_loss: 10.7492 - val_accuracy: 0.1667\n",
      "Epoch 12/40\n",
      "20/20 [==============================] - 8s 406ms/step - loss: 0.2539 - accuracy: 0.9450 - val_loss: 9.0182 - val_accuracy: 0.2508\n",
      "Epoch 13/40\n",
      "20/20 [==============================] - 10s 533ms/step - loss: 0.1745 - accuracy: 0.9583 - val_loss: 8.7132 - val_accuracy: 0.1677\n",
      "Epoch 14/40\n",
      "20/20 [==============================] - 10s 524ms/step - loss: 0.1375 - accuracy: 0.9667 - val_loss: 8.4498 - val_accuracy: 0.1777\n",
      "Epoch 15/40\n",
      "20/20 [==============================] - 10s 532ms/step - loss: 0.1154 - accuracy: 0.9800 - val_loss: 6.4193 - val_accuracy: 0.2628\n",
      "Epoch 16/40\n",
      "20/20 [==============================] - 8s 420ms/step - loss: 0.0866 - accuracy: 0.9850 - val_loss: 6.9319 - val_accuracy: 0.2363\n",
      "Epoch 17/40\n",
      "20/20 [==============================] - 10s 514ms/step - loss: 0.0678 - accuracy: 0.9883 - val_loss: 5.6020 - val_accuracy: 0.3943\n",
      "Epoch 18/40\n",
      "20/20 [==============================] - 10s 531ms/step - loss: 0.0916 - accuracy: 0.9850 - val_loss: 5.4497 - val_accuracy: 0.4210\n",
      "Epoch 19/40\n",
      "20/20 [==============================] - 10s 515ms/step - loss: 0.0968 - accuracy: 0.9817 - val_loss: 5.0721 - val_accuracy: 0.4020\n",
      "Epoch 20/40\n",
      "20/20 [==============================] - 10s 532ms/step - loss: 0.0583 - accuracy: 0.9867 - val_loss: 5.2788 - val_accuracy: 0.3900\n",
      "Epoch 21/40\n",
      "20/20 [==============================] - 10s 525ms/step - loss: 0.0719 - accuracy: 0.9900 - val_loss: 3.9588 - val_accuracy: 0.5265\n",
      "Epoch 22/40\n",
      "20/20 [==============================] - 9s 473ms/step - loss: 0.0524 - accuracy: 0.9933 - val_loss: 4.1873 - val_accuracy: 0.4943\n",
      "Epoch 23/40\n",
      "20/20 [==============================] - 8s 420ms/step - loss: 0.0676 - accuracy: 0.9850 - val_loss: 2.9443 - val_accuracy: 0.6197\n",
      "Epoch 24/40\n",
      "20/20 [==============================] - 9s 462ms/step - loss: 0.1025 - accuracy: 0.9800 - val_loss: 2.4087 - val_accuracy: 0.5923\n",
      "Epoch 25/40\n",
      "20/20 [==============================] - 9s 452ms/step - loss: 0.1026 - accuracy: 0.9833 - val_loss: 1.6915 - val_accuracy: 0.6553\n",
      "Epoch 26/40\n",
      "20/20 [==============================] - 8s 435ms/step - loss: 0.0849 - accuracy: 0.9850 - val_loss: 1.3508 - val_accuracy: 0.7163\n",
      "Epoch 27/40\n",
      "20/20 [==============================] - 9s 465ms/step - loss: 0.0699 - accuracy: 0.9833 - val_loss: 1.3495 - val_accuracy: 0.7518\n",
      "Epoch 28/40\n",
      "20/20 [==============================] - 8s 399ms/step - loss: 0.1115 - accuracy: 0.9750 - val_loss: 1.3093 - val_accuracy: 0.7785\n",
      "Epoch 29/40\n",
      "20/20 [==============================] - 11s 583ms/step - loss: 0.0696 - accuracy: 0.9867 - val_loss: 1.2028 - val_accuracy: 0.7977\n",
      "Epoch 30/40\n",
      "20/20 [==============================] - 10s 538ms/step - loss: 0.0541 - accuracy: 0.9967 - val_loss: 1.3057 - val_accuracy: 0.7968\n",
      "Epoch 31/40\n",
      "20/20 [==============================] - 11s 565ms/step - loss: 0.0717 - accuracy: 0.9900 - val_loss: 1.3385 - val_accuracy: 0.8167\n",
      "Epoch 32/40\n",
      "20/20 [==============================] - 9s 470ms/step - loss: 0.0804 - accuracy: 0.9817 - val_loss: 1.6474 - val_accuracy: 0.7973\n",
      "Epoch 33/40\n",
      "20/20 [==============================] - 10s 521ms/step - loss: 0.0835 - accuracy: 0.9883 - val_loss: 1.3625 - val_accuracy: 0.8125\n",
      "Epoch 34/40\n",
      "20/20 [==============================] - 9s 485ms/step - loss: 0.0832 - accuracy: 0.9883 - val_loss: 1.5288 - val_accuracy: 0.8077\n",
      "Epoch 35/40\n",
      "20/20 [==============================] - 10s 495ms/step - loss: 0.0569 - accuracy: 0.9917 - val_loss: 1.5517 - val_accuracy: 0.8147\n",
      "Epoch 36/40\n",
      "20/20 [==============================] - 9s 450ms/step - loss: 0.0469 - accuracy: 0.9967 - val_loss: 1.7058 - val_accuracy: 0.8093\n",
      "Epoch 37/40\n",
      "20/20 [==============================] - 9s 479ms/step - loss: 0.0548 - accuracy: 0.9967 - val_loss: 1.7561 - val_accuracy: 0.8087\n",
      "Epoch 38/40\n",
      "20/20 [==============================] - 3042s 160s/step - loss: 0.0433 - accuracy: 0.9933 - val_loss: 1.6862 - val_accuracy: 0.8180\n",
      "Epoch 39/40\n",
      "20/20 [==============================] - 2975s 157s/step - loss: 0.0493 - accuracy: 0.9950 - val_loss: 1.9252 - val_accuracy: 0.8065\n",
      "Epoch 40/40\n",
      "20/20 [==============================] - 1917s 101s/step - loss: 0.0501 - accuracy: 0.9950 - val_loss: 1.8301 - val_accuracy: 0.8197\n",
      "final accuracy: 0.8196666836738586\n",
      "shpae of private data: (30, 28, 28)\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-12 01:12:47.953607: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - ETA: 0s - loss: 2.4880 - accuracy: 0.6000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-12 01:12:51.363178: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 2824s 149s/step - loss: 2.4880 - accuracy: 0.6000 - val_loss: 1.5098 - val_accuracy: 0.3105\n",
      "Epoch 2/40\n",
      "20/20 [==============================] - 2091s 110s/step - loss: 0.9515 - accuracy: 0.7950 - val_loss: 2.1577 - val_accuracy: 0.2213\n",
      "Epoch 3/40\n",
      "20/20 [==============================] - 1985s 104s/step - loss: 0.8149 - accuracy: 0.8500 - val_loss: 3.6286 - val_accuracy: 0.1667\n",
      "Epoch 4/40\n",
      "20/20 [==============================] - 3100s 163s/step - loss: 0.8642 - accuracy: 0.8367 - val_loss: 4.4426 - val_accuracy: 0.1667\n",
      "Epoch 5/40\n",
      "20/20 [==============================] - 3095s 163s/step - loss: 0.9958 - accuracy: 0.8617 - val_loss: 4.9547 - val_accuracy: 0.1667\n",
      "Epoch 6/40\n",
      "20/20 [==============================] - 1937s 102s/step - loss: 0.5672 - accuracy: 0.8967 - val_loss: 6.0699 - val_accuracy: 0.1667\n",
      "Epoch 7/40\n",
      "20/20 [==============================] - 1864s 98s/step - loss: 0.5100 - accuracy: 0.9150 - val_loss: 5.4612 - val_accuracy: 0.1667\n",
      "Epoch 8/40\n",
      "20/20 [==============================] - 1927s 101s/step - loss: 0.3975 - accuracy: 0.9167 - val_loss: 7.7953 - val_accuracy: 0.1667\n",
      "Epoch 9/40\n",
      "20/20 [==============================] - 2704s 142s/step - loss: 0.2761 - accuracy: 0.9417 - val_loss: 8.7354 - val_accuracy: 0.1667\n",
      "Epoch 10/40\n",
      "20/20 [==============================] - 1088s 57s/step - loss: 0.1657 - accuracy: 0.9633 - val_loss: 8.9828 - val_accuracy: 0.1667\n",
      "Epoch 11/40\n",
      "20/20 [==============================] - 2845s 101s/step - loss: 0.1419 - accuracy: 0.9683 - val_loss: 8.9928 - val_accuracy: 0.1667\n",
      "Epoch 12/40\n",
      "20/20 [==============================] - 2192s 115s/step - loss: 0.1456 - accuracy: 0.9800 - val_loss: 7.3763 - val_accuracy: 0.1667\n",
      "Epoch 13/40\n",
      "20/20 [==============================] - 10s 516ms/step - loss: 0.1030 - accuracy: 0.9767 - val_loss: 6.1077 - val_accuracy: 0.1698\n",
      "Epoch 14/40\n",
      "20/20 [==============================] - 8s 434ms/step - loss: 0.1531 - accuracy: 0.9733 - val_loss: 6.4194 - val_accuracy: 0.1743\n",
      "Epoch 15/40\n",
      "20/20 [==============================] - 6s 290ms/step - loss: 0.1453 - accuracy: 0.9733 - val_loss: 5.1295 - val_accuracy: 0.2057\n",
      "Epoch 16/40\n",
      "20/20 [==============================] - 6s 291ms/step - loss: 0.1210 - accuracy: 0.9817 - val_loss: 5.0389 - val_accuracy: 0.3130\n",
      "Epoch 17/40\n",
      "20/20 [==============================] - 7s 373ms/step - loss: 0.0861 - accuracy: 0.9917 - val_loss: 4.2154 - val_accuracy: 0.3062\n",
      "Epoch 18/40\n",
      "20/20 [==============================] - 7s 375ms/step - loss: 0.0671 - accuracy: 0.9917 - val_loss: 4.0820 - val_accuracy: 0.3482\n",
      "Epoch 19/40\n",
      "20/20 [==============================] - 7s 386ms/step - loss: 0.0929 - accuracy: 0.9800 - val_loss: 2.3456 - val_accuracy: 0.5113\n",
      "Epoch 20/40\n",
      "20/20 [==============================] - 8s 391ms/step - loss: 0.0966 - accuracy: 0.9850 - val_loss: 2.3239 - val_accuracy: 0.4917\n",
      "Epoch 21/40\n",
      "20/20 [==============================] - 8s 397ms/step - loss: 0.0702 - accuracy: 0.9850 - val_loss: 2.0603 - val_accuracy: 0.5522\n",
      "Epoch 22/40\n",
      "20/20 [==============================] - 6s 294ms/step - loss: 0.0779 - accuracy: 0.9850 - val_loss: 1.5788 - val_accuracy: 0.6113\n",
      "Epoch 23/40\n",
      "20/20 [==============================] - 7s 383ms/step - loss: 0.0663 - accuracy: 0.9883 - val_loss: 1.5817 - val_accuracy: 0.6460\n",
      "Epoch 24/40\n",
      "20/20 [==============================] - 6s 323ms/step - loss: 0.0957 - accuracy: 0.9867 - val_loss: 1.7770 - val_accuracy: 0.6645\n",
      "Epoch 25/40\n",
      "20/20 [==============================] - 6s 291ms/step - loss: 0.0987 - accuracy: 0.9850 - val_loss: 1.5266 - val_accuracy: 0.7328\n",
      "Epoch 26/40\n",
      "20/20 [==============================] - 7s 357ms/step - loss: 0.0853 - accuracy: 0.9900 - val_loss: 1.3448 - val_accuracy: 0.7523\n",
      "Epoch 27/40\n",
      "20/20 [==============================] - 6s 290ms/step - loss: 0.0627 - accuracy: 0.9883 - val_loss: 1.0904 - val_accuracy: 0.7997\n",
      "Epoch 28/40\n",
      "20/20 [==============================] - 5s 262ms/step - loss: 0.0672 - accuracy: 0.9883 - val_loss: 1.1683 - val_accuracy: 0.7850\n",
      "Epoch 29/40\n",
      "20/20 [==============================] - 3s 175ms/step - loss: 0.0971 - accuracy: 0.9850 - val_loss: 1.2890 - val_accuracy: 0.7842\n",
      "Epoch 30/40\n",
      "20/20 [==============================] - 4s 209ms/step - loss: 0.0802 - accuracy: 0.9850 - val_loss: 1.3079 - val_accuracy: 0.8068\n",
      "Epoch 31/40\n",
      "20/20 [==============================] - 4s 227ms/step - loss: 0.0597 - accuracy: 0.9900 - val_loss: 1.5248 - val_accuracy: 0.7937\n",
      "Epoch 32/40\n",
      "20/20 [==============================] - 6s 308ms/step - loss: 0.0693 - accuracy: 0.9850 - val_loss: 1.4653 - val_accuracy: 0.8020\n",
      "Epoch 33/40\n",
      "20/20 [==============================] - 4s 217ms/step - loss: 0.1148 - accuracy: 0.9783 - val_loss: 2.0134 - val_accuracy: 0.7572\n",
      "Epoch 34/40\n",
      "20/20 [==============================] - 4s 192ms/step - loss: 0.1604 - accuracy: 0.9667 - val_loss: 2.0154 - val_accuracy: 0.8030\n",
      "Epoch 35/40\n",
      "20/20 [==============================] - 4s 195ms/step - loss: 0.1154 - accuracy: 0.9767 - val_loss: 2.0149 - val_accuracy: 0.8100\n",
      "Epoch 36/40\n",
      "20/20 [==============================] - 4s 225ms/step - loss: 0.1167 - accuracy: 0.9817 - val_loss: 2.0711 - val_accuracy: 0.8002\n",
      "Epoch 37/40\n",
      "20/20 [==============================] - 5s 235ms/step - loss: 0.1451 - accuracy: 0.9683 - val_loss: 2.3085 - val_accuracy: 0.7970\n",
      "Epoch 38/40\n",
      "20/20 [==============================] - 4s 234ms/step - loss: 0.1390 - accuracy: 0.9683 - val_loss: 2.6042 - val_accuracy: 0.7935\n",
      "Epoch 39/40\n",
      "20/20 [==============================] - 5s 247ms/step - loss: 0.2309 - accuracy: 0.9567 - val_loss: 2.2505 - val_accuracy: 0.8220\n",
      "Epoch 40/40\n",
      "20/20 [==============================] - 4s 189ms/step - loss: 0.2176 - accuracy: 0.9733 - val_loss: 2.7653 - val_accuracy: 0.8118\n",
      "final accuracy: 0.8118333220481873\n",
      "shpae of private data: (30, 28, 28)\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-12 08:56:20.828556: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - ETA: 0s - loss: 2.5176 - accuracy: 0.6000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-12 08:56:22.745402: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 7s 273ms/step - loss: 2.5176 - accuracy: 0.6000 - val_loss: 1.6214 - val_accuracy: 0.4685\n",
      "Epoch 2/40\n",
      "20/20 [==============================] - 4s 191ms/step - loss: 1.4839 - accuracy: 0.7817 - val_loss: 2.5155 - val_accuracy: 0.1770\n",
      "Epoch 3/40\n",
      "20/20 [==============================] - 4s 187ms/step - loss: 1.1037 - accuracy: 0.8217 - val_loss: 3.0551 - val_accuracy: 0.2020\n",
      "Epoch 4/40\n",
      "20/20 [==============================] - 5s 251ms/step - loss: 0.7116 - accuracy: 0.8750 - val_loss: 3.6250 - val_accuracy: 0.2733\n",
      "Epoch 5/40\n",
      "20/20 [==============================] - 5s 253ms/step - loss: 0.6313 - accuracy: 0.9017 - val_loss: 4.2772 - val_accuracy: 0.1667\n",
      "Epoch 6/40\n",
      "20/20 [==============================] - 4s 194ms/step - loss: 0.3591 - accuracy: 0.9217 - val_loss: 4.5837 - val_accuracy: 0.1668\n",
      "Epoch 7/40\n",
      "20/20 [==============================] - 5s 262ms/step - loss: 0.2742 - accuracy: 0.9267 - val_loss: 5.1891 - val_accuracy: 0.1667\n",
      "Epoch 8/40\n",
      "20/20 [==============================] - 5s 235ms/step - loss: 0.3542 - accuracy: 0.9367 - val_loss: 5.2607 - val_accuracy: 0.1668\n",
      "Epoch 9/40\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.4301 - accuracy: 0.9150 - val_loss: 6.2938 - val_accuracy: 0.1667\n",
      "Epoch 10/40\n",
      "20/20 [==============================] - 3s 174ms/step - loss: 0.4270 - accuracy: 0.9217 - val_loss: 5.5582 - val_accuracy: 0.1667\n",
      "Epoch 11/40\n",
      "20/20 [==============================] - 4s 186ms/step - loss: 0.2103 - accuracy: 0.9567 - val_loss: 4.7789 - val_accuracy: 0.2647\n",
      "Epoch 12/40\n",
      "20/20 [==============================] - 3s 167ms/step - loss: 0.1896 - accuracy: 0.9633 - val_loss: 5.2819 - val_accuracy: 0.1713\n",
      "Epoch 13/40\n",
      "20/20 [==============================] - 4s 206ms/step - loss: 0.1679 - accuracy: 0.9717 - val_loss: 4.4299 - val_accuracy: 0.2040\n",
      "Epoch 14/40\n",
      "20/20 [==============================] - 4s 231ms/step - loss: 0.1398 - accuracy: 0.9700 - val_loss: 4.8068 - val_accuracy: 0.2578\n",
      "Epoch 15/40\n",
      "20/20 [==============================] - 5s 244ms/step - loss: 0.1023 - accuracy: 0.9833 - val_loss: 4.8203 - val_accuracy: 0.1712\n",
      "Epoch 16/40\n",
      "20/20 [==============================] - 5s 262ms/step - loss: 0.0684 - accuracy: 0.9933 - val_loss: 3.7249 - val_accuracy: 0.2247\n",
      "Epoch 17/40\n",
      "20/20 [==============================] - 4s 211ms/step - loss: 0.0648 - accuracy: 0.9900 - val_loss: 3.6170 - val_accuracy: 0.3097\n",
      "Epoch 18/40\n",
      "20/20 [==============================] - 4s 191ms/step - loss: 0.1038 - accuracy: 0.9817 - val_loss: 3.2312 - val_accuracy: 0.3638\n",
      "Epoch 19/40\n",
      "20/20 [==============================] - 4s 194ms/step - loss: 0.1019 - accuracy: 0.9817 - val_loss: 2.8562 - val_accuracy: 0.4193\n",
      "Epoch 20/40\n",
      "20/20 [==============================] - 4s 204ms/step - loss: 0.0859 - accuracy: 0.9900 - val_loss: 2.1537 - val_accuracy: 0.4918\n",
      "Epoch 21/40\n",
      "20/20 [==============================] - 4s 230ms/step - loss: 0.0565 - accuracy: 0.9933 - val_loss: 2.2552 - val_accuracy: 0.4858\n",
      "Epoch 22/40\n",
      "20/20 [==============================] - 5s 250ms/step - loss: 0.0576 - accuracy: 0.9950 - val_loss: 1.3551 - val_accuracy: 0.6380\n",
      "Epoch 23/40\n",
      "20/20 [==============================] - 5s 243ms/step - loss: 0.0542 - accuracy: 0.9950 - val_loss: 1.3744 - val_accuracy: 0.6685\n",
      "Epoch 24/40\n",
      "20/20 [==============================] - 4s 227ms/step - loss: 0.0841 - accuracy: 0.9933 - val_loss: 1.2234 - val_accuracy: 0.7055\n",
      "Epoch 25/40\n",
      "20/20 [==============================] - 4s 216ms/step - loss: 0.0428 - accuracy: 1.0000 - val_loss: 1.1107 - val_accuracy: 0.7445\n",
      "Epoch 26/40\n",
      "20/20 [==============================] - 5s 263ms/step - loss: 0.0425 - accuracy: 0.9983 - val_loss: 1.1457 - val_accuracy: 0.7592\n",
      "Epoch 27/40\n",
      "20/20 [==============================] - 4s 212ms/step - loss: 0.0427 - accuracy: 0.9983 - val_loss: 1.0408 - val_accuracy: 0.7985\n",
      "Epoch 28/40\n",
      "20/20 [==============================] - 4s 188ms/step - loss: 0.0399 - accuracy: 0.9983 - val_loss: 1.2411 - val_accuracy: 0.7750\n",
      "Epoch 29/40\n",
      "20/20 [==============================] - 4s 228ms/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 1.1231 - val_accuracy: 0.8048\n",
      "Epoch 30/40\n",
      "20/20 [==============================] - 5s 264ms/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 1.1867 - val_accuracy: 0.8077\n",
      "Epoch 31/40\n",
      "20/20 [==============================] - 4s 202ms/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 1.3185 - val_accuracy: 0.7893\n",
      "Epoch 32/40\n",
      "20/20 [==============================] - 5s 252ms/step - loss: 0.0461 - accuracy: 0.9967 - val_loss: 1.5277 - val_accuracy: 0.7960\n",
      "Epoch 33/40\n",
      "20/20 [==============================] - 5s 272ms/step - loss: 0.0694 - accuracy: 0.9967 - val_loss: 1.5395 - val_accuracy: 0.7883\n",
      "Epoch 34/40\n",
      "20/20 [==============================] - 4s 209ms/step - loss: 0.0524 - accuracy: 0.9950 - val_loss: 1.5977 - val_accuracy: 0.8118\n",
      "Epoch 35/40\n",
      "20/20 [==============================] - 4s 194ms/step - loss: 0.0607 - accuracy: 0.9900 - val_loss: 1.5080 - val_accuracy: 0.8197\n",
      "Epoch 36/40\n",
      "20/20 [==============================] - 4s 204ms/step - loss: 0.0595 - accuracy: 0.9900 - val_loss: 1.9396 - val_accuracy: 0.7950\n",
      "Epoch 37/40\n",
      "20/20 [==============================] - 4s 193ms/step - loss: 0.0863 - accuracy: 0.9867 - val_loss: 1.5613 - val_accuracy: 0.8052\n",
      "Epoch 38/40\n",
      "20/20 [==============================] - 7s 383ms/step - loss: 0.0717 - accuracy: 0.9900 - val_loss: 1.7859 - val_accuracy: 0.8062\n",
      "Epoch 39/40\n",
      "20/20 [==============================] - 7s 383ms/step - loss: 0.0635 - accuracy: 0.9883 - val_loss: 1.8475 - val_accuracy: 0.8070\n",
      "Epoch 40/40\n",
      "20/20 [==============================] - 6s 337ms/step - loss: 0.0846 - accuracy: 0.9817 - val_loss: 2.3753 - val_accuracy: 0.7892\n",
      "final accuracy: 0.7891666889190674\n",
      "shpae of private data: (30, 28, 28)\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-12 08:59:20.285116: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - ETA: 0s - loss: 3.0497 - accuracy: 0.5833"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-12 08:59:22.285031: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 8s 413ms/step - loss: 3.0497 - accuracy: 0.5833 - val_loss: 1.5370 - val_accuracy: 0.4047\n",
      "Epoch 2/40\n",
      "20/20 [==============================] - 8s 393ms/step - loss: 1.6674 - accuracy: 0.7667 - val_loss: 3.1496 - val_accuracy: 0.2217\n",
      "Epoch 3/40\n",
      "20/20 [==============================] - 6s 298ms/step - loss: 1.1046 - accuracy: 0.8217 - val_loss: 3.1573 - val_accuracy: 0.1667\n",
      "Epoch 4/40\n",
      "20/20 [==============================] - 8s 413ms/step - loss: 0.8991 - accuracy: 0.8333 - val_loss: 3.7584 - val_accuracy: 0.2215\n",
      "Epoch 5/40\n",
      "20/20 [==============================] - 8s 424ms/step - loss: 0.4868 - accuracy: 0.8983 - val_loss: 4.6733 - val_accuracy: 0.1993\n",
      "Epoch 6/40\n",
      "20/20 [==============================] - 8s 411ms/step - loss: 0.4236 - accuracy: 0.9067 - val_loss: 5.3082 - val_accuracy: 0.1678\n",
      "Epoch 7/40\n",
      "20/20 [==============================] - 8s 424ms/step - loss: 0.3033 - accuracy: 0.9317 - val_loss: 5.8970 - val_accuracy: 0.2035\n",
      "Epoch 8/40\n",
      "20/20 [==============================] - 8s 402ms/step - loss: 0.2170 - accuracy: 0.9450 - val_loss: 6.6775 - val_accuracy: 0.1718\n",
      "Epoch 9/40\n",
      "20/20 [==============================] - 6s 308ms/step - loss: 0.2975 - accuracy: 0.9300 - val_loss: 6.3074 - val_accuracy: 0.1745\n",
      "Epoch 10/40\n",
      "20/20 [==============================] - 7s 342ms/step - loss: 0.2094 - accuracy: 0.9550 - val_loss: 6.2363 - val_accuracy: 0.2535\n",
      "Epoch 11/40\n",
      "20/20 [==============================] - 6s 331ms/step - loss: 0.1418 - accuracy: 0.9583 - val_loss: 5.9630 - val_accuracy: 0.1713\n",
      "Epoch 12/40\n",
      "20/20 [==============================] - 6s 325ms/step - loss: 0.1047 - accuracy: 0.9733 - val_loss: 6.6635 - val_accuracy: 0.2590\n",
      "Epoch 13/40\n",
      "20/20 [==============================] - 7s 343ms/step - loss: 0.1387 - accuracy: 0.9683 - val_loss: 7.6108 - val_accuracy: 0.1858\n",
      "Epoch 14/40\n",
      "20/20 [==============================] - 6s 300ms/step - loss: 0.1822 - accuracy: 0.9717 - val_loss: 5.7681 - val_accuracy: 0.1805\n",
      "Epoch 15/40\n",
      "20/20 [==============================] - 8s 411ms/step - loss: 0.1299 - accuracy: 0.9717 - val_loss: 5.6298 - val_accuracy: 0.1662\n",
      "Epoch 16/40\n",
      "20/20 [==============================] - 8s 396ms/step - loss: 0.1028 - accuracy: 0.9750 - val_loss: 5.6398 - val_accuracy: 0.1750\n",
      "Epoch 17/40\n",
      "20/20 [==============================] - 7s 367ms/step - loss: 0.1598 - accuracy: 0.9750 - val_loss: 6.1434 - val_accuracy: 0.2427\n",
      "Epoch 18/40\n",
      "20/20 [==============================] - 8s 409ms/step - loss: 0.0744 - accuracy: 0.9900 - val_loss: 6.0932 - val_accuracy: 0.1768\n",
      "Epoch 19/40\n",
      "20/20 [==============================] - 8s 407ms/step - loss: 0.0699 - accuracy: 0.9883 - val_loss: 5.0320 - val_accuracy: 0.2368\n",
      "Epoch 20/40\n",
      "20/20 [==============================] - 7s 388ms/step - loss: 0.0952 - accuracy: 0.9850 - val_loss: 3.8505 - val_accuracy: 0.3280\n",
      "Epoch 21/40\n",
      "20/20 [==============================] - 6s 315ms/step - loss: 0.0503 - accuracy: 0.9967 - val_loss: 2.7491 - val_accuracy: 0.4470\n",
      "Epoch 22/40\n",
      "20/20 [==============================] - 7s 375ms/step - loss: 0.0700 - accuracy: 0.9917 - val_loss: 2.4476 - val_accuracy: 0.4895\n",
      "Epoch 23/40\n",
      "20/20 [==============================] - 8s 394ms/step - loss: 0.0867 - accuracy: 0.9883 - val_loss: 1.9372 - val_accuracy: 0.5760\n",
      "Epoch 24/40\n",
      "20/20 [==============================] - 8s 399ms/step - loss: 0.0706 - accuracy: 0.9867 - val_loss: 1.5071 - val_accuracy: 0.6408\n",
      "Epoch 25/40\n",
      "20/20 [==============================] - 6s 325ms/step - loss: 0.0692 - accuracy: 0.9867 - val_loss: 1.2362 - val_accuracy: 0.7118\n",
      "Epoch 26/40\n",
      "20/20 [==============================] - 6s 315ms/step - loss: 0.0572 - accuracy: 0.9900 - val_loss: 1.7519 - val_accuracy: 0.6305\n",
      "Epoch 27/40\n",
      "20/20 [==============================] - 7s 383ms/step - loss: 0.0847 - accuracy: 0.9783 - val_loss: 1.0537 - val_accuracy: 0.7710\n",
      "Epoch 28/40\n",
      "20/20 [==============================] - 8s 411ms/step - loss: 0.0771 - accuracy: 0.9833 - val_loss: 1.2344 - val_accuracy: 0.7672\n",
      "Epoch 29/40\n",
      "20/20 [==============================] - 8s 422ms/step - loss: 0.1075 - accuracy: 0.9783 - val_loss: 1.5432 - val_accuracy: 0.7803\n",
      "Epoch 30/40\n",
      "20/20 [==============================] - 8s 405ms/step - loss: 0.3802 - accuracy: 0.9350 - val_loss: 1.6153 - val_accuracy: 0.7852\n",
      "Epoch 31/40\n",
      "20/20 [==============================] - 8s 390ms/step - loss: 0.3209 - accuracy: 0.9483 - val_loss: 1.7719 - val_accuracy: 0.8058\n",
      "Epoch 32/40\n",
      "20/20 [==============================] - 8s 390ms/step - loss: 0.2557 - accuracy: 0.9667 - val_loss: 2.1179 - val_accuracy: 0.7825\n",
      "Epoch 33/40\n",
      "20/20 [==============================] - 7s 342ms/step - loss: 0.2981 - accuracy: 0.9517 - val_loss: 2.6749 - val_accuracy: 0.7942\n",
      "Epoch 34/40\n",
      "20/20 [==============================] - 6s 312ms/step - loss: 0.4231 - accuracy: 0.9450 - val_loss: 2.8537 - val_accuracy: 0.7710\n",
      "Epoch 35/40\n",
      "20/20 [==============================] - 7s 379ms/step - loss: 0.2103 - accuracy: 0.9650 - val_loss: 2.5351 - val_accuracy: 0.7967\n",
      "Epoch 36/40\n",
      "20/20 [==============================] - 7s 363ms/step - loss: 0.0980 - accuracy: 0.9883 - val_loss: 2.4784 - val_accuracy: 0.8085\n",
      "Epoch 37/40\n",
      "20/20 [==============================] - 10s 527ms/step - loss: 0.0650 - accuracy: 0.9950 - val_loss: 2.4232 - val_accuracy: 0.8095\n",
      "Epoch 38/40\n",
      "20/20 [==============================] - 8s 404ms/step - loss: 0.0806 - accuracy: 0.9917 - val_loss: 2.3313 - val_accuracy: 0.8143\n",
      "Epoch 39/40\n",
      "20/20 [==============================] - 8s 410ms/step - loss: 0.0562 - accuracy: 0.9967 - val_loss: 2.2365 - val_accuracy: 0.8137\n",
      "Epoch 40/40\n",
      "20/20 [==============================] - 8s 427ms/step - loss: 0.0854 - accuracy: 0.9900 - val_loss: 2.4674 - val_accuracy: 0.8065\n",
      "final accuracy: 0.8065000176429749\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "central_trials = [] \n",
    "for i in range(5) : \n",
    "    tf.keras.backend.clear_session()\n",
    "    input_shape = private_data[0][\"X\"].shape[1:]\n",
    "\n",
    "    cbs = [EarlyStopping(monitor=\"val_accuracy\", min_delta=0.001, patience=7, restore_best_weights=True)]\n",
    "    cbs = [] \n",
    "\n",
    "    item = model_config[0]\n",
    "    model_name = item[\"model_type\"]\n",
    "    model_params = item[\"params\"]\n",
    "    model_ub = CANDIDATE_MODELS[model_name](n_classes=n_classes, \n",
    "                                        input_shape=input_shape,\n",
    "                                        **model_params)\n",
    "    model_ub.compile(optimizer=tf.keras.optimizers.Adam(lr = 1e-3),\n",
    "                        loss = \"sparse_categorical_crossentropy\", \n",
    "                        metrics = [\"accuracy\"])\n",
    "    print(\"shpae of private data:\", private_data[0][\"X\"].shape)\n",
    "    ub_history = model_ub.fit(new_total_private_data['X'], new_total_private_data['y'],\n",
    "                    batch_size = 30, epochs = 40, shuffle=True, verbose = True, \n",
    "                    validation_data = [private_test_data[\"X\"], private_test_data[\"y\"]],\n",
    "                    callbacks=[cbs])\n",
    "\n",
    "    central_trials.append(ub_history.history[\"val_accuracy\"])\n",
    "    print(\"final accuracy:\", ub_history.history[\"val_accuracy\"][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8098000049591064,\n",
       " [0.8218333125114441,\n",
       "  0.8196666836738586,\n",
       "  0.8118333220481873,\n",
       "  0.7891666889190674,\n",
       "  0.8065000176429749])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([acc[-1] for acc in central_trials]), [acc[-1] for acc in central_trials]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'local_trials' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/gadmohamed/Desktop/live repos/Drone-LoRa-SOM-CFedAKD/fl_src/local_central_training.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gadmohamed/Desktop/live%20repos/Drone-LoRa-SOM-CFedAKD/fl_src/local_central_training.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m np\u001b[39m.\u001b[39mmean(local_trials), np\u001b[39m.\u001b[39mstd(local_trials)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'local_trials' is not defined"
     ]
    }
   ],
   "source": [
    "np.mean(local_trials), np.std(local_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.49766083560884,\n",
       " 0.27189877306606575,\n",
       " [[0.5148333311080933,\n",
       "   0.21383333206176758,\n",
       "   0.1666666716337204,\n",
       "   0.1666666716337204,\n",
       "   0.1666666716337204,\n",
       "   0.1666666716337204,\n",
       "   0.1666666716337204,\n",
       "   0.1666666716337204,\n",
       "   0.20516666769981384,\n",
       "   0.1666666716337204,\n",
       "   0.20533333718776703,\n",
       "   0.1666666716337204,\n",
       "   0.16699999570846558,\n",
       "   0.1665000021457672,\n",
       "   0.2134999930858612,\n",
       "   0.3986666798591614,\n",
       "   0.36683332920074463,\n",
       "   0.43033334612846375,\n",
       "   0.5625,\n",
       "   0.6355000138282776,\n",
       "   0.6215000152587891,\n",
       "   0.6726666688919067,\n",
       "   0.749666690826416,\n",
       "   0.6791666746139526,\n",
       "   0.7103333473205566,\n",
       "   0.7528333067893982,\n",
       "   0.6464999914169312,\n",
       "   0.7541666626930237,\n",
       "   0.7941666841506958,\n",
       "   0.793666660785675,\n",
       "   0.8071666955947876,\n",
       "   0.8109999895095825,\n",
       "   0.8111666440963745,\n",
       "   0.8165000081062317,\n",
       "   0.8195000290870667,\n",
       "   0.8116666674613953,\n",
       "   0.8205000162124634,\n",
       "   0.8149999976158142,\n",
       "   0.8243333101272583,\n",
       "   0.8218333125114441],\n",
       "  [0.3995000123977661,\n",
       "   0.18666666746139526,\n",
       "   0.1666666716337204,\n",
       "   0.19050000607967377,\n",
       "   0.21316666901111603,\n",
       "   0.1666666716337204,\n",
       "   0.2318333387374878,\n",
       "   0.17366667091846466,\n",
       "   0.21316666901111603,\n",
       "   0.1863333284854889,\n",
       "   0.1666666716337204,\n",
       "   0.25083333253860474,\n",
       "   0.16766667366027832,\n",
       "   0.17766666412353516,\n",
       "   0.2628333270549774,\n",
       "   0.23633334040641785,\n",
       "   0.3943333327770233,\n",
       "   0.42100000381469727,\n",
       "   0.4020000100135803,\n",
       "   0.38999998569488525,\n",
       "   0.5264999866485596,\n",
       "   0.49433332681655884,\n",
       "   0.6196666955947876,\n",
       "   0.5923333168029785,\n",
       "   0.6553333401679993,\n",
       "   0.7163333296775818,\n",
       "   0.7518333196640015,\n",
       "   0.7785000205039978,\n",
       "   0.7976666688919067,\n",
       "   0.796833336353302,\n",
       "   0.8166666626930237,\n",
       "   0.7973333597183228,\n",
       "   0.8125,\n",
       "   0.8076666593551636,\n",
       "   0.8146666884422302,\n",
       "   0.809333324432373,\n",
       "   0.8086666464805603,\n",
       "   0.8180000185966492,\n",
       "   0.8065000176429749,\n",
       "   0.8196666836738586],\n",
       "  [0.31049999594688416,\n",
       "   0.2213333398103714,\n",
       "   0.1666666716337204,\n",
       "   0.1666666716337204,\n",
       "   0.1666666716337204,\n",
       "   0.1666666716337204,\n",
       "   0.1666666716337204,\n",
       "   0.1666666716337204,\n",
       "   0.1666666716337204,\n",
       "   0.1666666716337204,\n",
       "   0.1666666716337204,\n",
       "   0.1666666716337204,\n",
       "   0.16983333230018616,\n",
       "   0.1743333339691162,\n",
       "   0.2056666612625122,\n",
       "   0.31299999356269836,\n",
       "   0.3061666786670685,\n",
       "   0.34816667437553406,\n",
       "   0.5113333463668823,\n",
       "   0.49166667461395264,\n",
       "   0.5521666407585144,\n",
       "   0.6113333106040955,\n",
       "   0.6460000276565552,\n",
       "   0.6644999980926514,\n",
       "   0.7328333258628845,\n",
       "   0.7523333430290222,\n",
       "   0.7996666431427002,\n",
       "   0.7850000262260437,\n",
       "   0.784166693687439,\n",
       "   0.8068333268165588,\n",
       "   0.793666660785675,\n",
       "   0.8019999861717224,\n",
       "   0.7571666836738586,\n",
       "   0.8029999732971191,\n",
       "   0.8100000023841858,\n",
       "   0.800166666507721,\n",
       "   0.796999990940094,\n",
       "   0.7935000061988831,\n",
       "   0.8220000267028809,\n",
       "   0.8118333220481873],\n",
       "  [0.4684999883174896,\n",
       "   0.1770000010728836,\n",
       "   0.20200000703334808,\n",
       "   0.273333340883255,\n",
       "   0.1666666716337204,\n",
       "   0.1668333262205124,\n",
       "   0.1666666716337204,\n",
       "   0.1668333262205124,\n",
       "   0.1666666716337204,\n",
       "   0.1666666716337204,\n",
       "   0.26466667652130127,\n",
       "   0.17133332788944244,\n",
       "   0.20399999618530273,\n",
       "   0.257833331823349,\n",
       "   0.17116667330265045,\n",
       "   0.22466666996479034,\n",
       "   0.3096666634082794,\n",
       "   0.36383333802223206,\n",
       "   0.4193333387374878,\n",
       "   0.49183332920074463,\n",
       "   0.4858333468437195,\n",
       "   0.6380000114440918,\n",
       "   0.6685000061988831,\n",
       "   0.7055000066757202,\n",
       "   0.7444999814033508,\n",
       "   0.7591666579246521,\n",
       "   0.7985000014305115,\n",
       "   0.7749999761581421,\n",
       "   0.8048333525657654,\n",
       "   0.8076666593551636,\n",
       "   0.7893333435058594,\n",
       "   0.7960000038146973,\n",
       "   0.7883333563804626,\n",
       "   0.8118333220481873,\n",
       "   0.8196666836738586,\n",
       "   0.7950000166893005,\n",
       "   0.8051666617393494,\n",
       "   0.8061666488647461,\n",
       "   0.8069999814033508,\n",
       "   0.7891666889190674],\n",
       "  [0.4046666622161865,\n",
       "   0.22166666388511658,\n",
       "   0.1666666716337204,\n",
       "   0.2214999943971634,\n",
       "   0.1993333399295807,\n",
       "   0.1678333282470703,\n",
       "   0.20350000262260437,\n",
       "   0.171833336353302,\n",
       "   0.1745000034570694,\n",
       "   0.2535000145435333,\n",
       "   0.17133332788944244,\n",
       "   0.2590000033378601,\n",
       "   0.18583333492279053,\n",
       "   0.18050000071525574,\n",
       "   0.16616666316986084,\n",
       "   0.17499999701976776,\n",
       "   0.24266666173934937,\n",
       "   0.17683333158493042,\n",
       "   0.2368333339691162,\n",
       "   0.328000009059906,\n",
       "   0.44699999690055847,\n",
       "   0.4894999861717224,\n",
       "   0.5759999752044678,\n",
       "   0.64083331823349,\n",
       "   0.7118333578109741,\n",
       "   0.6305000185966492,\n",
       "   0.7710000276565552,\n",
       "   0.7671666741371155,\n",
       "   0.7803333401679993,\n",
       "   0.7851666808128357,\n",
       "   0.8058333396911621,\n",
       "   0.7825000286102295,\n",
       "   0.7941666841506958,\n",
       "   0.7710000276565552,\n",
       "   0.79666668176651,\n",
       "   0.8084999918937683,\n",
       "   0.809499979019165,\n",
       "   0.8143333196640015,\n",
       "   0.8136666417121887,\n",
       "   0.8065000176429749]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(central_trials), np.std(central_trials), central_trials"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
