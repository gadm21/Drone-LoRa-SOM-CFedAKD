{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gadmohamed/miniforge3/envs/env_tf/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from data_utils import * \n",
    "from model_utils import *\n",
    "from utils import FLClient, FLServer\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "import os\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CIFAR-10 for FL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "(50000, 32, 32, 3) (50000,) (10000, 32, 32, 3) (10000,) (50000, 10) (10000, 10)\n",
      "(50000, 32, 32, 3) (50000,) (10000, 32, 32, 3) (10000,) (50000, 100) (10000, 100)\n"
     ]
    }
   ],
   "source": [
    "dataset = 'cifar10'\n",
    "num_classes = 10 if dataset == 'cifar10' else 100 \n",
    "pub_num_classes = 100 if num_classes == 10 else 10\n",
    "datadir = '../data'\n",
    "partition = 'iid' \n",
    "n_parties = 5\n",
    "beta = 0.5\n",
    "\n",
    "(X_train, y_train, X_test, y_test, net_dataidx_map) = partition_data('cifar10', datadir=datadir, partition = partition, n_parties = n_parties, beta = beta)\n",
    "(X_train_public, y_train_public, X_test_public, y_test_public, net_dataidx_map_public) = partition_data('cifar100', datadir=datadir, partition = 'iid', n_parties = 10, beta = 0.5)\n",
    "y_train_cat = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test_cat = to_categorical(y_test, num_classes=num_classes)\n",
    "y_train_public_cat = to_categorical(y_train_public, num_classes=pub_num_classes)\n",
    "y_test_public_cat = to_categorical(y_test_public, num_classes=pub_num_classes)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, y_train_cat.shape, y_test_cat.shape)\n",
    "print(X_train_public.shape, y_train_public.shape, X_test_public.shape, y_test_public.shape, y_train_public_cat.shape, y_test_public_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 32, 32, 3) (5000, 100)\n",
      "client  0   (10000, 32, 32, 3) (10000, 10)\n",
      "(10000, 32, 32, 3) (10000, 10)\n",
      "\n",
      "client  1   (10000, 32, 32, 3) (10000, 10)\n",
      "(10000, 32, 32, 3) (10000, 10)\n",
      "\n",
      "client  2   (10000, 32, 32, 3) (10000, 10)\n",
      "(10000, 32, 32, 3) (10000, 10)\n",
      "\n",
      "client  3   (10000, 32, 32, 3) (10000, 10)\n",
      "(10000, 32, 32, 3) (10000, 10)\n",
      "\n",
      "client  4   (10000, 32, 32, 3) (10000, 10)\n",
      "(10000, 32, 32, 3) (10000, 10)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "local_sets = [] \n",
    "test_sets = []\n",
    "public_set = (X_train_public[net_dataidx_map_public[0]], y_train_public_cat[net_dataidx_map_public[0]])\n",
    "for i in range(n_parties):\n",
    "    local_sets.append((X_train[net_dataidx_map[i]], y_train_cat[net_dataidx_map[i]]))\n",
    "    test_sets.append((X_test, y_test_cat))\n",
    "    \n",
    "print(public_set[0].shape, public_set[1].shape)\n",
    "for i in range(n_parties):\n",
    "    print('client ', i, ' ', local_sets[i][0].shape, local_sets[i][1].shape)\n",
    "    print(test_sets[i][0].shape, test_sets[i][1].shape)\n",
    "    print() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation_method = 'soft_labels'\n",
    "aug = False\n",
    "weighting = 'uniform'\n",
    "private =   False\n",
    "hyperparameter_tuning = False\n",
    "C = 1\n",
    "\n",
    "fl_params = {\n",
    "    'client_num': len(local_sets),\n",
    "    'tot_T': 50, \n",
    "    'C': C,\n",
    "    'local_sets': local_sets,\n",
    "    'test_sets': test_sets,\n",
    "    'public_set': public_set,\n",
    "    'batch_size': 32,\n",
    "    'epochs': 3, \n",
    "    'lr': 0.005,\n",
    "    'aggregate': aggregation_method, # 'grads', 'compressed_soft_labels', 'soft_labels'\n",
    "    'hyperparameter_tuning': hyperparameter_tuning, \n",
    "    'weighting': weighting, # 'uniform', 'performance_based'\n",
    "    'default_client_id': 1, \n",
    "    'augment': aug, \n",
    "    'private': private,\n",
    "    'max_grad_norm': 1.0,\n",
    "    'delta': 1e-4,\n",
    "    'epsilon': 5,\n",
    "    'local_benchmark_epochs': 70\n",
    "}\n",
    "\n",
    "N_pub = len(fl_params['public_set'][0])\n",
    "exp_path = f\"../fl_results/{dataset}/DP{private}/N_pub{N_pub}/Agg{fl_params['aggregate']}_C{fl_params['C']}_HT{fl_params['hyperparameter_tuning']}_Aug{fl_params['augment']}_W{fl_params['weighting']}\"\n",
    "fl_params['exp_path'] = exp_path\n",
    "server = FLServer(fl_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.5848,  0.1384,  0.7466,  1.3653, -1.4365,  1.2980,  0.0129, -0.7767,\n",
       "          -0.5729,  0.6902]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[0.0356, 0.0733, 0.1347, 0.2501, 0.0152, 0.2338, 0.0647, 0.0294, 0.0360,\n",
       "          0.1273]], grad_fn=<SoftmaxBackward0>))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = X_train[0] \n",
    "sample = np.expand_dims(sample, axis=0)\n",
    "# to tensor \n",
    "t_sample = torch.from_numpy(sample).float()\n",
    "server.clients[0].model(t_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation_method = 'compressed_soft_labels'\n",
    "aug = False\n",
    "weighting = 'uniform'\n",
    "private =   False\n",
    "hyperparameter_tuning = False\n",
    "C = 1\n",
    "\n",
    "fl_params = {\n",
    "    'client_num': len(local_sets),\n",
    "    'tot_T': 50, \n",
    "    'C': C,\n",
    "    'local_sets': local_sets,\n",
    "    'test_sets': test_sets,\n",
    "    'public_set': public_set,\n",
    "    'batch_size': 32,\n",
    "    'epochs': 3, \n",
    "    'lr': 0.005,\n",
    "    'aggregate': aggregation_method, # 'grads', 'compressed_soft_labels', 'soft_labels'\n",
    "    'hyperparameter_tuning': hyperparameter_tuning, \n",
    "    'weighting': weighting, # 'uniform', 'performance_based'\n",
    "    'default_client_id': 1, \n",
    "    'augment': aug, \n",
    "    'private': private,\n",
    "    'max_grad_norm': 1.0,\n",
    "    'delta': 1e-4,\n",
    "    'epsilon': 5,\n",
    "    'local_benchmark_epochs': 70\n",
    "}\n",
    "\n",
    "N_pub = len(fl_params['public_set'][0])\n",
    "exp_path = f\"../fl_results/{dataset}/DP{private}/N_pub{N_pub}/Agg{fl_params['aggregate']}_C{fl_params['C']}_HT{fl_params['hyperparameter_tuning']}_Aug{fl_params['augment']}_W{fl_params['weighting']}\"\n",
    "fl_params['exp_path'] = exp_path\n",
    "compressed_server = FLServer(fl_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50.0, 200.0, 3332.952)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import size_of \n",
    "soft_labels = server.clients[0].get_soft_labels()\n",
    "compressed_soft_labels = compressed_server.clients[0].get_soft_labels(normalize = True, compress = True)\n",
    "clientmodel = server.clients[0].model\n",
    "ssize = size_of(soft_labels, size = 'KB')\n",
    "cssize = size_of(compressed_soft_labels, size = 'KB')\n",
    "clientmodel_state = clientmodel.state_dict()\n",
    "msize = size_of(clientmodel_state, size = 'KB')\n",
    "\n",
    "cssize, ssize, msize \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation_method = 'weights'\n",
    "aug = False\n",
    "weighting = 'uniform'\n",
    "private =   False\n",
    "hyperparameter_tuning = False\n",
    "C = 1\n",
    "\n",
    "fl_params = {\n",
    "    'client_num': len(local_sets),\n",
    "    'tot_T': 50, \n",
    "    'C': C,\n",
    "    'local_sets': local_sets,\n",
    "    'test_sets': test_sets,\n",
    "    'public_set': public_set,\n",
    "    'batch_size': 32,\n",
    "    'epochs': 3, \n",
    "    'lr': 0.005,\n",
    "    'aggregate': aggregation_method, # 'grads', 'compressed_soft_labels', 'soft_labels'\n",
    "    'hyperparameter_tuning': hyperparameter_tuning, \n",
    "    'weighting': weighting, # 'uniform', 'performance_based'\n",
    "    'default_client_id': 1, \n",
    "    'augment': aug, \n",
    "    'private': private,\n",
    "    'max_grad_norm': 1.0,\n",
    "    'delta': 1e-4,\n",
    "    'epsilon': 5,\n",
    "    'local_benchmark_epochs': 70\n",
    "}\n",
    "\n",
    "N_pub = len(fl_params['public_set'][0])\n",
    "exp_path = f\"../fl_results/{dataset}/DP{private}/N_pub{N_pub}/Agg{fl_params['aggregate']}_C{fl_params['C']}_HT{fl_params['hyperparameter_tuning']}_Aug{fl_params['augment']}_W{fl_params['weighting']}\"\n",
    "fl_params['exp_path'] = exp_path\n",
    "server = FLServer(fl_params)\n",
    "\n",
    "FL_acc = []\n",
    "for t in range(fl_params['tot_T']):\n",
    "    avg_acc, min_acc, max_acc, avg_train_acc = server.global_update()\n",
    "    FL_acc.append(avg_acc)\n",
    "    print(f\"Round {t} accuracy: avg: {avg_acc} min: {min_acc}  max: {max_acc} avg_train: {avg_train_acc}\")\n",
    "print(\"Final accuracy: \", FL_acc[-1])\n",
    "print() \n",
    "\n",
    "client_accs = []\n",
    "for c, client in enumerate(server.clients):\n",
    "    acc = client.local_benchmark()\n",
    "    client_accs.append(acc)\n",
    "    print(f\"Client {c} local benchmark accuracy: {acc}\")\n",
    "print(\"Client accuracies: \", client_accs, \"  \", np.mean(client_accs))\n",
    "print()\n",
    "\n",
    "server.save_assets()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FedMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation_method = 'soft_labels'\n",
    "aug = False\n",
    "weighting = 'uniform'\n",
    "private =   False\n",
    "hyperparameter_tuning = False\n",
    "C = 1\n",
    "\n",
    "\n",
    "fl_params = {\n",
    "    'client_num': len(local_sets),\n",
    "    'tot_T': 50, \n",
    "    'C': C,\n",
    "    'local_sets': local_sets,\n",
    "    'test_sets': test_sets,\n",
    "    'public_set': public_set,\n",
    "    'batch_size': 32,\n",
    "    'epochs': 3, \n",
    "    'lr': 0.005,\n",
    "    'aggregate': aggregation_method, # 'grads', 'compressed_soft_labels', 'soft_labels'\n",
    "    'hyperparameter_tuning': hyperparameter_tuning, \n",
    "    'weighting': weighting, # 'uniform', 'performance_based'\n",
    "    'default_client_id': 1, \n",
    "    'augment': aug, \n",
    "    'private': private,\n",
    "    'max_grad_norm': 1.0,\n",
    "    'delta': 1e-4,\n",
    "    'epsilon': 5,\n",
    "    'local_benchmark_epochs': 70\n",
    "}\n",
    "\n",
    "N_pub = len(fl_params['public_set'][0])\n",
    "exp_path = f\"../fl_results/{dataset}/DP{private}/N_pub{N_pub}/Agg{fl_params['aggregate']}_C{fl_params['C']}_HT{fl_params['hyperparameter_tuning']}_Aug{fl_params['augment']}_W{fl_params['weighting']}\"\n",
    "fl_params['exp_path'] = exp_path\n",
    "server = FLServer(fl_params)\n",
    "\n",
    "FL_acc = []\n",
    "for t in range(fl_params['tot_T']):\n",
    "    avg_acc, min_acc, max_acc, avg_train_acc = server.global_update()\n",
    "    FL_acc.append(avg_acc)\n",
    "    print(f\"Round {t} accuracy: avg: {avg_acc} min: {min_acc}  max: {max_acc} avg_train: {avg_train_acc}\")\n",
    "print(\"Final accuracy: \", FL_acc[-1])\n",
    "print() \n",
    "\n",
    "# client_accs = []\n",
    "# for c, client in enumerate(server.clients):\n",
    "#     acc = client.local_benchmark()\n",
    "#     client_accs.append(acc)\n",
    "#     print(f\"Client {c} local benchmark accuracy: {acc}\")\n",
    "# print(\"Client accuracies: \", client_accs, \"  \", np.mean(client_accs))\n",
    "# print()\n",
    "\n",
    "server.save_assets()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CFedAKD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation_method = 'compressed_soft_labels'\n",
    "aug = True\n",
    "weighting = 'uniform'\n",
    "private =   False\n",
    "hyperparameter_tuning = False\n",
    "C = 1\n",
    "\n",
    "\n",
    "fl_params = {\n",
    "    'client_num': len(local_sets),\n",
    "    'tot_T': 50, \n",
    "    'C': C,\n",
    "    'local_sets': local_sets,\n",
    "    'test_sets': test_sets,\n",
    "    'public_set': public_set,\n",
    "    'batch_size': 32,\n",
    "    'epochs': 3, \n",
    "    'lr': 0.005,\n",
    "    'aggregate': aggregation_method, # 'grads', 'compressed_soft_labels', 'soft_labels'\n",
    "    'hyperparameter_tuning': hyperparameter_tuning, \n",
    "    'weighting': weighting, # 'uniform', 'performance_based'\n",
    "    'default_client_id': 1, \n",
    "    'augment': aug, \n",
    "    'private': private,\n",
    "    'max_grad_norm': 1.0,\n",
    "    'delta': 1e-4,\n",
    "    'epsilon': 5,\n",
    "    'local_benchmark_epochs': 70\n",
    "}\n",
    "\n",
    "N_pub = len(fl_params['public_set'][0])\n",
    "exp_path = f\"../fl_results/{dataset}/DP{private}/N_pub{N_pub}/Agg{fl_params['aggregate']}_C{fl_params['C']}_HT{fl_params['hyperparameter_tuning']}_Aug{fl_params['augment']}_W{fl_params['weighting']}\"\n",
    "fl_params['exp_path'] = exp_path\n",
    "server = FLServer(fl_params)\n",
    "\n",
    "FL_acc = []\n",
    "for t in range(fl_params['tot_T']):\n",
    "    avg_acc, min_acc, max_acc, avg_train_acc = server.global_update()\n",
    "    FL_acc.append(avg_acc)\n",
    "    print(f\"Round {t} accuracy: avg: {avg_acc} min: {min_acc}  max: {max_acc} avg_train: {avg_train_acc}\")\n",
    "print(\"Final accuracy: \", FL_acc[-1])\n",
    "print() \n",
    "\n",
    "# client_accs = []\n",
    "# for c, client in enumerate(server.clients):\n",
    "#     acc = client.local_benchmark()\n",
    "#     client_accs.append(acc)\n",
    "#     print(f\"Client {c} local benchmark accuracy: {acc}\")\n",
    "# print(\"Client accuracies: \", client_accs, \"  \", np.mean(client_accs))\n",
    "# print()\n",
    "\n",
    "server.save_assets()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FedAKD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation_method = 'soft_labels'\n",
    "aug = True\n",
    "weighting = 'uniform'\n",
    "private =   False\n",
    "hyperparameter_tuning = False\n",
    "C = 1\n",
    "\n",
    "\n",
    "fl_params = {\n",
    "    'client_num': len(local_sets),\n",
    "    'tot_T': 50, \n",
    "    'C': C,\n",
    "    'local_sets': local_sets,\n",
    "    'test_sets': test_sets,\n",
    "    'public_set': public_set,\n",
    "    'batch_size': 32,\n",
    "    'epochs': 3, \n",
    "    'lr': 0.005,\n",
    "    'aggregate': aggregation_method, # 'grads', 'compressed_soft_labels', 'soft_labels'\n",
    "    'hyperparameter_tuning': hyperparameter_tuning, \n",
    "    'weighting': weighting, # 'uniform', 'performance_based'\n",
    "    'default_client_id': 1, \n",
    "    'augment': aug, \n",
    "    'private': private,\n",
    "    'max_grad_norm': 1.0,\n",
    "    'delta': 1e-4,\n",
    "    'epsilon': 5,\n",
    "    'local_benchmark_epochs': 70\n",
    "}\n",
    "\n",
    "N_pub = len(fl_params['public_set'][0])\n",
    "exp_path = f\"../fl_results/{dataset}/DP{private}/N_pub{N_pub}/Agg{fl_params['aggregate']}_C{fl_params['C']}_HT{fl_params['hyperparameter_tuning']}_Aug{fl_params['augment']}_W{fl_params['weighting']}\"\n",
    "fl_params['exp_path'] = exp_path\n",
    "server = FLServer(fl_params)\n",
    "\n",
    "FL_acc = []\n",
    "for t in range(fl_params['tot_T']):\n",
    "    avg_acc, min_acc, max_acc, avg_train_acc = server.global_update()\n",
    "    FL_acc.append(avg_acc)\n",
    "    print(f\"Round {t} accuracy: avg: {avg_acc} min: {min_acc}  max: {max_acc} avg_train: {avg_train_acc}\")\n",
    "print(\"Final accuracy: \", FL_acc[-1])\n",
    "print() \n",
    "\n",
    "# client_accs = []\n",
    "# for c, client in enumerate(server.clients):\n",
    "#     acc = client.local_benchmark()\n",
    "#     client_accs.append(acc)\n",
    "#     print(f\"Client {c} local benchmark accuracy: {acc}\")\n",
    "# print(\"Client accuracies: \", client_accs, \"  \", np.mean(client_accs))\n",
    "# print()\n",
    "\n",
    "server.save_assets()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
